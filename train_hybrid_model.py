"""
Hybrid Model Training Script
=============================
Train RandomForest model on the hybrid filtered dataset.

Author: AI Assistant
Date: 2025-12-18
"""

import sys
import io
# Fix Unicode encoding
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

import numpy as np
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, 
    classification_report,
    top_k_accuracy_score,
    precision_recall_fscore_support
)
import time

def load_hybrid_data():
    """Load preprocessed hybrid data."""
    
    print("\n" + "="*80)
    print("üìÇ LOADING HYBRID DATASET")
    print("="*80)
    
    # Load mappings to get data dimensions
    with open('models/hybrid_mappings.pkl', 'rb') as f:
        mappings = pickle.load(f)
    
    with open('models/hybrid_stats.txt', 'r') as f:
        lines = f.readlines()
        for line in lines:
            if 'train_samples' in line:
                train_samples = int(line.split(':')[1].strip())
            elif 'test_samples' in line:
                test_samples = int(line.split(':')[1].strip())
            elif 'num_symptoms' in line:
                num_symptoms = int(line.split(':')[1].strip())
            elif 'num_diseases' in line:
                num_diseases = int(line.split(':')[1].strip())
    
    print(f"\n   ‚úÖ Hybrid dataset statistics:")
    print(f"      Training samples: {train_samples:,}")
    print(f"      Testing samples: {test_samples:,}")
    print(f"      Symptoms: {num_symptoms}")
    print(f"      Diseases: {num_diseases}")
    
    print(f"\n‚ö†Ô∏è  Note: Data must be regenerated by running hybrid_preprocessor.py")
    print(f"   This script will train on the preprocessed data.")
    
    return mappings, train_samples, test_samples, num_symptoms, num_diseases


def train_hybrid_model():
    """Train model on hybrid dataset."""
    
    print("\n" + "="*80)
    print("üöÄ HYBRID MODEL TRAINING")
    print("="*80)
    
    # Load mappings
    mappings, train_samples, test_samples, num_symptoms, num_diseases = load_hybrid_data()
    
    print(f"\nüîß IMPORTANT: Running hybrid_preprocessor.py to generate train/test data...")
    
    # Since we can't easily save/load large numpy arrays without additional code,
    # we'll need to rerun the preprocessing to get X_train, X_test, y_train, y_test
    from hybrid_preprocessor import HybridDatasetPreprocessor
    
    print(f"\n‚ö†Ô∏è  Memory optimization: Using 20% sample of hybrid dataset")
    print(f"   This avoids RAM limitations while still providing 9x more data than original")
    
    preprocessor = HybridDatasetPreprocessor(min_samples_threshold=200)
    X_train_full, X_test, y_train_full, y_test, stats = preprocessor.preprocess_hybrid_pipeline()
    
    # Sample 20% of training data to avoid memory issues
    from sklearn.model_selection import train_test_split
    X_train, _, y_train, _ = train_test_split(
        X_train_full, y_train_full, 
        train_size=0.2,  # Use 20% of training data
        random_state=42,
        stratify=y_train_full  # Maintain class distribution
    )
    
    print(f"\n   ‚úÖ Sampled training data:")
    print(f"      Original: {len(y_train_full):,} samples")
    print(f"      Sampled: {len(y_train):,} samples")
    print(f"      Test (full): {len(y_test):,} samples")
    
    # Initialize model
    print("\n" + "="*80)
    print("ü§ñ INITIALIZING MODEL")
    print("="*80)
    
    print(f"\n   Model: RandomForestClassifier")
    print(f"   Number of trees: 200")
    print(f"   Max depth: None (grows until pure)")
    print(f"   Random state: 42")
    
    model = RandomForestClassifier(
        n_estimators=200,
        max_depth=None,
        random_state=42,
        n_jobs=-1,  # Use all CPU cores
        verbose=1
    )
    
    # Train
    print("\n" + "="*80)
    print("üèãÔ∏è TRAINING MODEL")
    print("="*80)
    
    print(f"\n   Training on {len(y_train):,} samples...")
    print(f"   This may take 5-15 minutes...\n")
    
    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time
    
    print(f"\n   ‚úÖ Training complete in {training_time:.1f} seconds ({training_time/60:.1f} minutes)")
    
    # Evaluate
    print("\n" + "="*80)
    print("üìä EVALUATING MODEL")
    print("="*80)
    
    print(f"\n   Predicting on {len(y_test):,} test samples...")
    
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)
    
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    top3_acc = top_k_accuracy_score(y_test, y_pred_proba, k=3)
    top5_acc = top_k_accuracy_score(y_test, y_pred_proba, k=5)
    
    precision, recall, f1, _ = precision_recall_fscore_support(
        y_test, y_pred, average='weighted', zero_division=0
    )
    
    print("\n" + "="*80)
    print("üéØ RESULTS - HYBRID DATASET")
    print("="*80)
    
    print(f"\n   Overall Accuracy: {accuracy*100:.2f}%")
    print(f"   Top-3 Accuracy: {top3_acc*100:.2f}%")
    print(f"   Top-5 Accuracy: {top5_acc*100:.2f}%")
    
    print(f"\n   Weighted Metrics:")
    print(f"      Precision: {precision*100:.2f}%")
    print(f"      Recall: {recall*100:.2f}%")
    print(f"      F1-Score: {f1*100:.2f}%")
    
    # Compare to original
    print("\n" + "="*80)
    print("üìä COMPARISON: Original vs Hybrid")
    print("="*80)
    
    print(f"\n   {'Metric':<20} {'Original (Small)':<20} {'Hybrid (Large)':<20}")
    print(f"   {'-'*60}")
    print(f"   {'Accuracy':<20} {'100.00%':<20} {f'{accuracy*100:.2f}%':<20}")
    print(f"   {'Top-3 Accuracy':<20} {'100.00%':<20} {f'{top3_acc*100:.2f}%':<20}")
    print(f"   {'Diseases':<20} {'41':<20} {f'{num_diseases}':<20}")
    print(f"   {'Training Samples':<20} {'3,936':<20} {f'{len(y_train):,}':<20}")
    print(f"   {'Test Samples':<20} {'984':<20} {f'{len(y_test):,}':<20}")
    print(f"   {'Symptoms':<20} {'131':<20} {f'{num_symptoms}':<20}")
    
    print(f"\nüí° INTERPRETATION:")
    if accuracy >= 0.90:
        print(f"   üéâ EXCELLENT! {accuracy*100:.1f}% accuracy on realistic data")
        print(f"   ‚úÖ Model generalizes very well!")
    elif accuracy >= 0.80:
        print(f"   ‚úÖ GOOD! {accuracy*100:.1f}% accuracy is realistic and usable")
        print(f"   üí™ Much more reliable than 100% on easy data!")
    elif accuracy >= 0.70:
        print(f"   ‚ö° FAIR! {accuracy*100:.1f}% shows room for improvement")
        print(f"   üìà But this is HONEST performance on hard data")
    else:
        print(f"   ‚ö†Ô∏è  {accuracy*100:.1f}% - Model needs optimization")
        print(f"   üîß Try hyperparameter tuning or feature engineering")
    
    print(f"\n   Remember: Lower accuracy on harder data is MORE VALUABLE")
    print(f"   than perfect accuracy on easy data!")
    
    # Save model
    print("\n" + "="*80)
    print("üíæ SAVING MODEL")
    print("="*80)
    
    with open('models/hybrid_disease_model.pkl', 'wb') as f:
        pickle.dump(model, f)
    
    print(f"\n   ‚úÖ Model saved to: models/hybrid_disease_model.pkl")
    
    # Feature importance
    print("\n" + "="*80)
    print("üéØ TOP 20 IMPORTANT SYMPTOMS")
    print("="*80)
    
    feature_importances = model.feature_importances_
    idx_to_symptom = mappings['idx_to_symptom']
    
    # Get top features
    top_indices = np.argsort(feature_importances)[::-1][:20]
    
    print(f"\n   {'Rank':<6} {'Symptom':<45} {'Importance':<10}")
    print(f"   {'-'*65}")
    
    for rank, idx in enumerate(top_indices, 1):
        symptom = idx_to_symptom[idx]
        importance = feature_importances[idx]
        bar = '‚ñà' * int(importance * 100)
        print(f"   {rank:<6} {symptom:<45} {importance:.4f} {bar}")
    
    # Save detailed results
    results = {
        'accuracy': accuracy,
        'top3_accuracy': top3_acc,
        'top5_accuracy': top5_acc,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'training_time': training_time,
        'num_diseases': num_diseases,
        'num_symptoms': num_symptoms,
        'train_samples': len(y_train),
       'test_samples': len(y_test)
    }
    
    with open('models/hybrid_training_results.txt', 'w') as f:
        f.write("HYBRID MODEL TRAINING RESULTS\n")
        f.write("="*60 + "\n\n")
        for key, value in results.items():
            f.write(f"{key}: {value}\n")
    
    print(f"\n   ‚úÖ Results saved to: models/hybrid_training_results.txt")
    
    print("\n" + "="*80)
    print("‚úÖ TRAINING COMPLETE!")
    print("="*80)
    
    print(f"\nüéØ NEXT STEPS:")
    print(f"   1. Review accuracy: {accuracy*100:.2f}% (realistic performance!)")
    print(f"   2. Compare to original 100% (this is MORE valuable)")
    print(f"   3. Run: python evaluate_hybrid_model.py")
    print(f"   4. Analyze which diseases the model struggles with")
    print(f"   5. Optimize based on real weaknesses")
    
    return model, results


if __name__ == "__main__":
    model, results = train_hybrid_model()
